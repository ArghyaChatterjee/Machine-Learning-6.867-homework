{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as opt\n",
    "import os\n",
    "from linear_regression import LinearRegression\n",
    "from gradient_descent import GradientDescent, quad, quadGrad\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--LAD Statistics--\n",
      "w_LAD = [ 0.81035512  1.58400184  0.19450814 -0.29554269]\n",
      "reg. SAE_train = 5.48407891659\n",
      "reg. SAE_validate = 7.52434313696\n",
      "reg. SAE_test = 13.8116332746\n",
      " \n",
      "-------------\n",
      "M = 0\n",
      "argmin lambda = 10.0\n",
      "reg. SAE_train = 18.2859136078\n",
      "reg. SAE_val = 13.8005613879\n",
      "reg. SAE_test = 18.8849417276\n",
      "----------------\n",
      " \n",
      " \n",
      "-------------\n",
      "M = 1\n",
      "argmin lambda = 0.0\n",
      "reg. SAE_train = 6.29138628172\n",
      "reg. SAE_val = 3.13794139109\n",
      "reg. SAE_test = 3.70944731458\n",
      "----------------\n",
      " \n",
      " \n",
      "-------------\n",
      "M = 2\n",
      "argmin lambda = 0.0502512562814\n",
      "reg. SAE_train = 6.59182150266\n",
      "reg. SAE_val = 3.19366125113\n",
      "reg. SAE_test = 4.10270495029\n",
      "----------------\n",
      " \n",
      " \n",
      "-------------\n",
      "M = 3\n",
      "argmin lambda = 6.08040201005\n",
      "reg. SAE_train = 12.8118898284\n",
      "reg. SAE_val = 6.81863263276\n",
      "reg. SAE_test = 9.13495655983\n",
      "----------------\n",
      " \n",
      " \n",
      "-------------\n",
      "M = 4\n",
      "argmin lambda = 3.56783919598\n",
      "reg. SAE_train = 11.5075789393\n",
      "reg. SAE_val = 6.59912544421\n",
      "reg. SAE_test = 8.26757416885\n",
      "----------------\n",
      " \n",
      " \n",
      "-------------\n",
      "M = 5\n",
      "argmin lambda = 8.74371859296\n",
      "reg. SAE_train = 12.9959479626\n",
      "reg. SAE_val = 6.98498838075\n",
      "reg. SAE_test = 13.3460807503\n",
      "----------------\n",
      " \n"
     ]
    }
   ],
   "source": [
    "def plot(lr,w, plot_sin=True, plot_test=True, plot_validate=True):\n",
    "    # plot sin(2*phi*x) in green\n",
    "    x_min = np.amin(lr.x)\n",
    "    x_max = np.amax(lr.x)\n",
    "    x = np.linspace(-3,3,1000)\n",
    "    M = lr.numFeatures - 1\n",
    "    \n",
    "    lr_temp = LinearRegression(x,x,lr.numFeatures-1)\n",
    "    reg_prediction = np.dot(lr_temp.phi,w)\n",
    "    \n",
    "    lr_validate = LinearRegression.fromFile(validate_filename, M)\n",
    "    lr_test = LinearRegression.fromFile(test_filename, M)\n",
    "    \n",
    "    plt.plot(x, reg_prediction, color='r')\n",
    "    \n",
    "    # the training set is plotted in blue\n",
    "    plt.scatter(lr.x, lr.y, color='r', marker='o',facecolors='none')\n",
    "    \n",
    "    # test set plotted in green\n",
    "    if plot_test:\n",
    "        plt.scatter(lr_test.x, lr_test.y, color='g', marker='o',facecolors='none')\n",
    "        \n",
    "    # validation set plotted in orange\n",
    "    if plot_test:\n",
    "        plt.scatter(lr_validate.x, lr_validate.y, color='b', marker='o',facecolors='none')\n",
    "              \n",
    "    plt.show()\n",
    "\n",
    "def gradDescentSAE(lr, verbose=False):\n",
    "    w_initial = 1.0*lr.reg()\n",
    "    \n",
    "    res = opt.minimize(lr.SAEwReg, w_initial)\n",
    "    \n",
    "    if verbose:\n",
    "        print \" \"\n",
    "        print \"--- Scipy Minimization Summary --- \"\n",
    "        print \"x_min is = \" + str(res.x)\n",
    "        print \"f_min is = \" + str(res.fun)\n",
    "        print \"numFunctionCalls = \" + str(res.nfev)\n",
    "    #     print \"numIterations = \" + str(res.nit)\n",
    "        print \"---------------------------- \"\n",
    "        print \" \"\n",
    "\n",
    "        plot(lr,res.x)\n",
    "    \n",
    "    return (lr, res.x)\n",
    "\n",
    "\n",
    "def computeLAD(M, lam, train, test, validate, verbose=True):\n",
    "    lr_train = LinearRegression.fromFile(train, M)\n",
    "    lr_validate = LinearRegression.fromFile(validate, M)\n",
    "    lr_test = LinearRegression.fromFile(test, M)\n",
    "    \n",
    "    lr_train.lam = lam\n",
    "    lr_validate.lam = lam\n",
    "    lr_test.lam = lam\n",
    "    \n",
    "    (_,w_LAD) = gradDescentSAE(lr_train)\n",
    "    \n",
    "    sae_train = lr_train.SAEwReg(w_LAD)\n",
    "    sae_test = lr_test.SAEwReg(w_LAD)\n",
    "    sae_validate = lr_validate.SAEwReg(w_LAD)\n",
    "    \n",
    "    if verbose:\n",
    "        print \"--LAD Statistics--\"\n",
    "        print \"w_LAD = \" + str(w_LAD)\n",
    "        print \"reg. SAE_train = \" + str(sae_train)\n",
    "        print \"reg. SAE_validate = \" + str(sae_validate)\n",
    "        print \"reg. SAE_test = \" + str(sae_test)\n",
    "\n",
    "    \n",
    "    return (sae_validate, sae_test, sae_train)\n",
    "\n",
    "\n",
    "def modelSelection(M, showPlot=False):\n",
    "    sseVal = lambda x: computeLAD(M, x, train_filename, test_filename, validate_filename, verbose=False)[0]\n",
    "    sseTest = lambda x: computeLAD(M, x, train_filename, test_filename, validate_filename, verbose=False)[1]\n",
    "    sseTrain = lambda x: computeLAD(M, x, train_filename, test_filename, validate_filename, verbose=False)[2]\n",
    "    \n",
    "    sseVal_vec = np.vectorize(sseVal)\n",
    "    sseTest_vec = np.vectorize(sseTest)\n",
    "    sseTrain_vec = np.vectorize(sseTrain)\n",
    "    \n",
    "    lam_vec = np.linspace(0,10,200)\n",
    "    a = sseVal_vec(lam_vec)\n",
    "    b = sseTest_vec(lam_vec)\n",
    "    c = sseTrain_vec(lam_vec)\n",
    "    \n",
    "    lam_min_idx = np.argmin(a)\n",
    "    lam_min = lam_vec[lam_min_idx]\n",
    "    \n",
    "    lr_train = LinearRegression.fromFile(train_filename, M)\n",
    "    (_,w_LAD) = gradDescentSAE(lr_train)\n",
    "    w_LAD = lr_train.ridge(lam_min) # NEED TO BE ABLE TO SPECIFY LAMBDA\n",
    "    \n",
    "\n",
    "    if showPlot:\n",
    "#         plt.plot(lam_vec, a, color='b')\n",
    "#         plt.plot(lam_vec, b, color='g')\n",
    "        plot(lr_train, w_LAD, plot_sin=False, plot_test=True, plot_validate=True)\n",
    "        plt.show()\n",
    "        \n",
    "    print \" \"\n",
    "    print \"-------------\"\n",
    "    print \"M = \" + str(M)\n",
    "    print \"argmin lambda = \" + str(lam_min)\n",
    "    print \"reg. SAE_train = \" + str(c[lam_min_idx])\n",
    "    print \"reg. SAE_val = \" + str(a[lam_min_idx])\n",
    "    print \"reg. SAE_test = \" + str(b[lam_min_idx])\n",
    "    print \"----------------\"\n",
    "    print \" \"\n",
    "\n",
    "\n",
    "filename = 'regress_train.txt'\n",
    "M = 1\n",
    "\n",
    "test_filename = \"regress_test.txt\"\n",
    "train_filename = \"regress_train.txt\"\n",
    "validate_filename = \"regress_validate.txt\"\n",
    "\n",
    "\n",
    "# # Example of just calling gradDescentSAE directly after calling an lr object\n",
    "# lr = LinearRegression.fromFile(filename, M=1)\n",
    "# lr.lam = 100\n",
    "# (lr, w) = gradDescentSAE(lr, verbose=True)\n",
    "\n",
    "# Example of calling computeLAD (which in turn calls gradDescentSAE)\n",
    "M = 3\n",
    "lam = 0.000001\n",
    "computeLAD(M, lam, train_filename, test_filename, validate_filename, verbose=True)\n",
    "\n",
    "\n",
    "for m in range(0,6):\n",
    "    modelSelection(m, showPlot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot(lr, w, plot_sin=True, plot_test=False, plot_validate=False):\n",
    "    # plot sin(2*phi*x) in green\n",
    "    x_min = np.amin(lr.x)\n",
    "    x_max = np.amax(lr.x)\n",
    "    x = np.linspace(-3,3,1000)\n",
    "    M = lr.numFeatures - 1\n",
    "    sin_x = np.sin(2*np.pi*x)\n",
    "    lr_temp = LinearRegression(x,x,lr.numFeatures-1)\n",
    "    reg_prediction = np.dot(lr_temp.phi,w)\n",
    "    \n",
    "    lr_validate = LinearRegression.fromFile(validate_filename, M)\n",
    "    lr_test = LinearRegression.fromFile(test_filename, M)\n",
    "    \n",
    "    \n",
    "    if plot_sin:\n",
    "        plt.plot(x,sin_x, color='g')\n",
    "        \n",
    "    plt.plot(x, reg_prediction, color='r')\n",
    "    \n",
    "    # the training set is plotted in blue\n",
    "    plt.scatter(lr.x, lr.y, color='r', marker='o',facecolors='none')\n",
    "    \n",
    "    # test set plotted in green\n",
    "    if plot_test:\n",
    "        plt.scatter(lr_test.x, lr_test.y, color='g', marker='o',facecolors='none')\n",
    "        \n",
    "    # validation set plotted in orange\n",
    "    if plot_test:\n",
    "        plt.scatter(lr_validate.x, lr_validate.y, color='b', marker='o',facecolors='none')\n",
    "        \n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "def plotRidge(M,lam):\n",
    "    lr = LinearRegression.fromFile(filename, M)\n",
    "    w_ridge = lr.ridge(lam)\n",
    "    sse = lr.SSE(w_ridge)\n",
    "    plot(lr,w_ridge)\n",
    "    print \" \"\n",
    "    print \"--Ridge Regression Statistics--\"\n",
    "    print \"w_ridge = \" + str(w_ridge)\n",
    "    print \"SSE = \" + str(sse) \n",
    "    \n",
    "\n",
    "def computeRidge(M, lam, train, test, validate, verbose=True):\n",
    "    lr_train = LinearRegression.fromFile(train, M)\n",
    "    lr_validate = LinearRegression.fromFile(validate, M)\n",
    "    lr_test = LinearRegression.fromFile(test, M)\n",
    "    \n",
    "    w_ridge = lr_train.ridge(lam)\n",
    "    sse_train = lr_train.SSE(w_ridge)\n",
    "    sse_test = lr_test.SSE(w_ridge)\n",
    "    sse_validate = lr_validate.SSE(w_ridge)\n",
    "    \n",
    "    if verbose:\n",
    "        print \"--Ridge Regression Statistics--\"\n",
    "        print \"w_ridge = \" + str(w_ridge)\n",
    "        print \"SSE_train = \" + str(sse_train)\n",
    "        print \"SSE_validate = \" + str(sse_validate)\n",
    "        print \"SSE_test = \" + str(sse_test)\n",
    "\n",
    "        plot(lr_train, w_ridge, plot_sin=False, plot_test=True, plot_validate=True)\n",
    "    \n",
    "    return (sse_validate, sse_test, sse_train)\n",
    "\n",
    "def modelSelection(M, showPlot=False):\n",
    "    sseVal = lambda x: computeRidge(M, x, train_filename, test_filename, validate_filename, verbose=False)[0]\n",
    "    sseTest = lambda x: computeRidge(M, x, train_filename, test_filename, validate_filename, verbose=False)[1]\n",
    "    sseTrain = lambda x: computeRidge(M, x, train_filename, test_filename, validate_filename, verbose=False)[2]\n",
    "    \n",
    "    sseVal_vec = np.vectorize(sseVal)\n",
    "    sseTest_vec = np.vectorize(sseTest)\n",
    "    sseTrain_vec = np.vectorize(sseTrain)\n",
    "    \n",
    "    lam_vec = np.linspace(0,10,200)\n",
    "    a = sseVal_vec(lam_vec)\n",
    "    b = sseTest_vec(lam_vec)\n",
    "    c = sseTrain_vec(lam_vec)\n",
    "    \n",
    "    lam_min_idx = np.argmin(a)\n",
    "    lam_min = lam_vec[lam_min_idx]\n",
    "    \n",
    "    lr_train = lr_train = LinearRegression.fromFile(train_filename, M)\n",
    "    w_ridge = lr_train.ridge(lam_min)\n",
    "    \n",
    "\n",
    "    if showPlot:\n",
    "#         plt.plot(lam_vec, a, color='b')\n",
    "#         plt.plot(lam_vec, b, color='g')\n",
    "        plot(lr_train, w_ridge, plot_sin=False, plot_test=True, plot_validate=True)\n",
    "        plt.show()\n",
    "        \n",
    "    print \" \"\n",
    "    print \"-------------\"\n",
    "    print \"M = \" + str(M)\n",
    "    print \"argmin lambda = \" + str(lam_min)\n",
    "    print \"SSE_train = \" + str(c[lam_min_idx])\n",
    "    print \"SSE_val = \" + str(a[lam_min_idx])\n",
    "    print \"SSE_test = \" + str(b[lam_min_idx])\n",
    "    print \"----------------\"\n",
    "    print \" \"\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "filename = \"curvefitting.txt\"\n",
    "test_filename = \"regress_test.txt\"\n",
    "train_filename = \"regress_train.txt\"\n",
    "validate_filename = \"regress_validate.txt\"\n",
    "M = 1\n",
    "lam =1.14\n",
    "# plotRidge(M, lam)\n",
    "computeLAD(M, lam, train_filename, test_filename, validate_filename, verbose=True)\n",
    "\n",
    "# sseVal = lambda x: computeRidge(M, x, train_filename, test_filename, validate_filename, verbose=False)[0]\n",
    "# sseTest = lambda x: computeRidge(M, x, train_filename, test_filename, validate_filename, verbose=False)[1]\n",
    "\n",
    "# sseVal_vec = np.vectorize(sseVal)\n",
    "# sseTest_vec = np.vectorize(sseTest)\n",
    "\n",
    "# lam_vec = np.linspace(0,10,100)\n",
    "# a = sseVal_vec(lam_vec)\n",
    "# b = sseTest_vec(lam_vec)\n",
    "\n",
    "# plt.plot(lam_vec, a, color='b')\n",
    "# plt.plot(lam_vec, b, color='g')\n",
    "\n",
    "for m in range(0,6):\n",
    "    modelSelection(m, showPlot=False)\n",
    "    \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sseVal_vec(np.array([1,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blog Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_train = LinearRegression.fromBlog(type='train')\n",
    "lr_validate = LinearRegression.fromBlog(type='val')\n",
    "lr_test = LinearRegression.fromBlog(type='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def computeBlogRidge(lam, verbose=True):\n",
    "    \n",
    "    print \"evaluating for a specific lambda\"\n",
    "    \n",
    "    w_ridge = lr_train.ridge(lam)\n",
    "    mse_train = lr_train.MSE(w_ridge)\n",
    "    mse_test = lr_test.MSE(w_ridge)\n",
    "    mse_validate = lr_validate.MSE(w_ridge)\n",
    "    \n",
    "    if verbose:\n",
    "        print \"--Ridge Regression Statistics--\"\n",
    "#         print \"w_ridge = \" + str(w_ridge)\n",
    "        print \"MSE_train = \" + str(mse_train)\n",
    "        print \"MSE_validate = \" + str(mse_validate)\n",
    "        print \"MSE_test = \" + str(mse_test)\n",
    "    \n",
    "    return (mse_validate, mse_test, mse_train)\n",
    "\n",
    "def blogModelSelection(showPlot=True):\n",
    "    sseVal = lambda x: computeBlogRidge(x, verbose=False)[0]\n",
    "    sseTest = lambda x: computeBlogRidge(x, verbose=False)[1]\n",
    "    sseTrain = lambda x: computeBlogRidge(x, verbose=False)[2]\n",
    "    num_obs = 1.0*np.shape(lr_train.phi)[0]\n",
    "    \n",
    "    sseVal_vec = np.vectorize(sseVal)\n",
    "    sseTest_vec = np.vectorize(sseTest)\n",
    "    sseTrain_vec = np.vectorize(sseTrain)\n",
    "    \n",
    "    lam_vec = num_obs*np.linspace(0.001,20,10)\n",
    "    a = sseVal_vec(lam_vec)\n",
    "    b = sseTest_vec(lam_vec)\n",
    "    c = sseTrain_vec(lam_vec)\n",
    "    \n",
    "    lam_min_idx = np.argmin(a)\n",
    "    lam_min = lam_vec[lam_min_idx]\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    if showPlot:\n",
    "#         plt.plot(lam_vec, c, color='r')\n",
    "#         plt.plot(lam_vec/num_obs, a, color='b')\n",
    "        plt.plot(lam_vec, b, color='g')\n",
    "        plt.show()\n",
    "        \n",
    "    print \" \"\n",
    "    print \"-------------\"\n",
    "    print \"argmin lambda = \" + str(lam_min)\n",
    "    print \"argmin lambda/num_obs = \" + str(lam_min/(num_obs))\n",
    "    print \"MSE_train = \" + str(c[lam_min_idx])\n",
    "    print \"MSE_val = \" + str(a[lam_min_idx])\n",
    "    print \"MSE_test = \" + str(b[lam_min_idx])\n",
    "    print \"----------------\"\n",
    "    print \" \" \n",
    "    \n",
    "\n",
    "# lr_train = LinearRegression.fromBlog(type='train')\n",
    "blogModelSelection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_obs = 31437\n",
    "computeBlogRidge(num_obs*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(lasso,_,_,_,_) = LinearRegression.fromLASSOData()\n",
    "np.shape(lasso.phi)\n",
    "\n",
    "\n",
    "w_reg = lasso.reg()\n",
    "print w_reg\n",
    "\n",
    "w = lasso.Lasso(0, w_0=w_reg)\n",
    "print w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
