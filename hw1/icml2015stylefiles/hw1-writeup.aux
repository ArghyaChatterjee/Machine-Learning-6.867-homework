\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\newlabel{grad-descent-iterations}{{1}{1}{Value of SSE at each iteration of our gradient descent algorithm, $\eta = 0.05$, $w_0 = 0$}{figure.1}{}}
\newlabel{ridge_m_3_lam_0-01}{{2}{2}{Ridge regression with $M = 3, \lambda = 0.01$. $SSE = 1.54$}{figure.2}{}}
\newlabel{ridge_m_3_lam_0-001}{{3}{2}{Ridge regression with $M = 3, \lambda = 0.001$. $SSE = 0.588$}{figure.3}{}}
\newlabel{ridge_m_9_lam_0-001}{{4}{2}{Ridge regression with $M = 9, \lambda = 0.001$. $SSE = 0.418$}{figure.4}{}}
\newlabel{model-selection}{{2}{2}{}{figure.4}{}}
\newlabel{m-4-model-selection}{{5}{3}{Ridge regression with $M = 3, \lambda = 0.85$. Train datapoints are red, validation are blue, and test are green}{figure.5}{}}
\newlabel{m-1-model-selection}{{6}{3}{Ridge regression with $M = 1, \lambda = 6.5$. Train datapoints are red, validation are blue, and test are green}{figure.6}{}}
\newlabel{blog-model-selection}{{7}{3}{The x-axis is $\hat {\lambda } = \frac {\lambda }{N}$ plotted against the MSE of the validation set on the y-axis}{figure.7}{}}
\newlabel{blog-model-select-test}{{8}{3}{The x-axis is $\hat {\lambda } = \frac {\lambda }{N}$ plotted against the MSE of the test set on the y-axis}{figure.8}{}}
\newlabel{submission}{{3}{3}{}{section.3}{}}
\citation{langley00}
\citation{anonymous}
\newlabel{author info}{{4.3}{5}{}{subsection.4.3}{}}
\newlabel{final author}{{4.3.2}{5}{}{subsubsection.4.3.2}{}}
\newlabel{icml-historical}{{9}{6}{Historical locations and number of accepted papers for International Machine Learning Conferences (ICML 1993 -- ICML 2008) and International Workshops on Machine Learning (ML 1988 -- ML 1992). At the time this figure was produced, the number of accepted papers for ICML 2008 was unknown and instead estimated}{figure.9}{}}
\citation{Samuel59}
\citation{Samuel59}
\citation{kearns89,Samuel59,mitchell80}
\citation{MachineLearningI}
\citation{Samuel59}
\citation{langley00}
\citation{Newell81}
\citation{DudaHart2nd}
\citation{MachineLearningI}
\citation{mitchell80}
\citation{kearns89}
\newlabel{alg:example}{{1}{7}{}{algorithm.1}{}}
\newlabel{sample-table}{{2}{7}{Classification accuracies for naive Bayes and flexible Bayes on various data sets}{table.2}{}}
\citation{langley00}
\bibdata{example_paper}
\bibstyle{icml2015}
